# Data Frames

1. pandas : rectangular data
```
each label : row name 下面的名字
each variable : column's name下面的名字
methods:
a.dataframe.head().. returns the first few rows (the “head” of the DataFrame).
b.dataframe.info() ... shows information on each of the columns, such as the data type and number of missing values.
c.dataframe.describe()....calculates a few summary statistics for each column.

attributes:
a.dataframe.values ...  A two-dimensional NumPy array of values.
b.dataframe.columns ...  An index of columns: the column names.
c.dataframe.index ...  An index for the rows: either row numbers or row names.
d.c.dataframe.shape... returns the number of rows and columns of the DataFrame.
```

2.Sorting and subsetting : subsetting 要用 [[]] double bracket , 因為結果要return 是dataframe [其他只要一個[]就好，一個[]可以選bracket name]
```
sorting:
df.sort_values("breed") ... one column
df.sort_values(["breed", "weight_kg"]) ....multiple columns
ex : homelessness_reg_fam = homelessness.sort_values(['region','family_members'],ascending=[True,False])
```
```
subsetting columns:
df[["col_a", "col_b"]] ... select multiple coiumns, outer bracket subset df, inner bracket select column names 

subsetting rows: 
3 Steps
1.Select the corresponding column
2.Set conditions on column
3.Use result(To return True values :) to select rows data

dogs[dogs["height_cm"] > 60]
dogs[dogs["color"] == "tan"]
dogs[(dogs["height_cm"] > 60) & (dogs["col_b"] == "tan")]

```
```
Subsetting rows by categorical variables ... select mutiple rows at the same time
3 Steps
1.Select the multiple corresponding column
2.Set conditions on column [use isin() method]
3.Use result(To return True values :) to select rows data
colors = ["brown", "black", "tan"]
condition = dogs["color"].isin(colors)
dogs[condition]
```
```
new columns
1.mutating
2.transforming a dataframe
3.feature engineering
```

# Aggregating data
1.mean and medium / max and min
```
sales['weekly_sales'].mean()
sales['weekly_sales'].median()
sales['date'].max()
sales['date'].min()
```

2.Efficient summaries 
```
The .agg() method allows you to apply your own custom functions to a DataFrame, and also multiple columns and multiple functions [Series 還是 series, dataframe 還是dataframe]

import numpy as np
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)
    
sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr,np.median])...outer bracket means dataframe, inner bracket means column name[panda series]

```
3. Cumulative statistics
```
1.df.cumsum()
2.df.cummax()
```

4. Counting : variable value counts
```
- drop same instance appeared more than once :
df.drop_duplicates(subset=['cola','colb'])
df[df["cola"]].drop_duplicates(subset='colb')

- Counting categorical variables
df["cola"].value_counts()
df["cola"].value_counts(normalize=True)..proportion
df['cola'].value_counts(sort=True, normalize=True) ... 排序依高到低＋比例顯示

```
5. groupby
```
.groupby('col name')把col name下面每個variable 整理起來
each label : row name 下面的名字
each variable : column's name下面的名字
df.groupby('column name') ... 變成一個panda dataframegroupyby，再去做column操作
df.groupby(['cola','colb'])['colc'].sum()...多個variable的groupby

ps.[numply float,numpy float, numpy float]也算是ndarray,不算list
ps..groupby() 後的type為pandas dataframegroupyby
ps.groupby()['col name']後的type 為 pandas seriesgroupyby
ps..sum()後的type為numpy.float
ps.pandas and ndarray都可以做element的計算
```

6.pivot_tables :  alternative way of groupby, but more convenient
```
The values argument of .pivot_table() takes in the name of the column you want to summarize.
The index argument of .pivot_table() takes in the name of the column you want to group by.
The aggfunc=[function]
ex: mean_sales_by_type = sales.pivot_table(values='weekly_sales',index='type')
ex:mean_med_sales_by_type = sales.pivot_table(values="weekly_sales", index="type", aggfunc=[np.mean, np.median])
ex :mean_sales_by_type_holiday = sales.pivot_table(values="weekly_sales", index="type", columns="is_holiday")
```






# slicing and indexing data
```

```


# creating and  visualizing data

```

```

 










































